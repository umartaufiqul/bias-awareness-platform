(this["webpackJsonpbias-awareness-platform"]=this["webpackJsonpbias-awareness-platform"]||[]).push([[0],{118:function(e,t,a){e.exports=a(241)},123:function(e,t,a){},125:function(e,t,a){},126:function(e,t,a){},127:function(e,t,a){},128:function(e,t,a){},229:function(e,t,a){},230:function(e,t,a){},231:function(e,t,a){e.exports=a.p+"static/media/dataset_fill.94d25a65.svg"},232:function(e,t,a){e.exports=a.p+"static/media/dataset.e73d48bf.svg"},233:function(e,t,a){e.exports=a.p+"static/media/classifier_fill.6e22b02e.svg"},234:function(e,t,a){e.exports=a.p+"static/media/classifier.9cfac40f.svg"},235:function(e,t,a){e.exports=a.p+"static/media/prediction_fill.aea17280.svg"},236:function(e,t,a){e.exports=a.p+"static/media/prediction.ae83db9c.svg"},237:function(e,t,a){},238:function(e,t,a){e.exports=a.p+"static/media/help.8a36d3fb.svg"},239:function(e,t,a){e.exports=a.p+"static/media/x-mark.898b1b0e.svg"},241:function(e,t,a){"use strict";a.r(t);var n=a(0),i=a.n(n),l=a(13),r=a.n(l),c=a(37),o=a(10),s=(a(123),a(124),a(125),a(5)),u=a(6),m=a(8),d=a(7),h=(a(126),function(e){Object(m.a)(a,e);var t=Object(d.a)(a);function a(){var e;Object(s.a)(this,a);for(var n=arguments.length,i=new Array(n),l=0;l<n;l++)i[l]=arguments[l];return(e=t.call.apply(t,[this].concat(i))).goToLink=function(){window.location.href=e.props.link},e}return Object(u.a)(a,[{key:"render",value:function(){return i.a.createElement("div",{className:this.props.className},i.a.createElement("button",{className:"button",onClick:this.goToLink},this.props.name))}}]),a}(n.Component)),p=a(102),f=a(73);var E=function(){return i.a.createElement("div",{className:"App"},i.a.createElement("h1",{className:"text-center"}," Activity 1. Bias in Hate Speech Detection "),i.a.createElement("p",null," In this activity, a member of high school board would like to have a feedback about their school facility and faculty. However, following the school policy, the board doesn't want to include feedbacks that include toxic or abusive words. On the other hand, the school board is concerned that some of the underrepresented group of student can be unnecessarily filtered out"),i.a.createElement(p.a,{className:"text-center"},i.a.createElement(f.a,{md:{span:3,offset:2}},i.a.createElement("div",{className:"comment-sample"}," The school lunch is delicious, but I wish the portion could be more fulfilling "),i.a.createElement("div",{className:"comment-label"}," Acceptable comment ")),i.a.createElement(f.a,{md:{span:3,offset:2}},i.a.createElement("div",{className:"comment-sample"}," The school lunch sucks! "),i.a.createElement("div",{className:"comment-label"}," Unacceptable "))),i.a.createElement("p",null," Your task is to create a model that can automatically detect and remove such feedback, while taking the school board concern into consideration"),i.a.createElement("div",{className:"text-center"},i.a.createElement(h,{name:"Start Activity",link:"/bias-awareness-platform/#/code"})))},b=(a(127),function(e){Object(m.a)(a,e);var t=Object(d.a)(a);function a(){return Object(s.a)(this,a),t.apply(this,arguments)}return Object(u.a)(a,[{key:"render",value:function(){return i.a.createElement("div",{className:"page-box code-notebook"},i.a.createElement("h1",{className:"text-center"}," Build the Model "),i.a.createElement("p",null," Build the classifier to detect the abusive and toxic feedbacks. For the purpose of the evaluation, use the variable ",i.a.createElement("span",null," dataset ")," as the initial data"),i.a.createElement("h2",null," Data Preprocessing "),i.a.createElement("textarea",{rows:"8"}),i.a.createElement("h2",null," Feature Generation "),i.a.createElement("textarea",{rows:"10"}),i.a.createElement("h2",null," Running the Model "),i.a.createElement("textarea",{rows:"5"}),i.a.createElement(h,{name:"Build",link:"/bias-awareness-platform/#/visualization",className:"text-center mt"}))}}]),a}(n.Component)),v=a(79),g=a(41),y=(a(128),function(e){Object(m.a)(a,e);var t=Object(d.a)(a);function a(e){var n;return Object(s.a)(this,a),(n=t.call(this,e)).state={current_stage:"1. Visualization"},n}return Object(u.a)(a,[{key:"render",value:function(){return i.a.createElement(v.a,{className:"justify-content-center",id:"navbar"},i.a.createElement(v.a.Brand,{id:"navbar-brand"},"Bias Awareness Platform"),i.a.createElement("div",{className:"mx-auto"},i.a.createElement(g.a,{title:this.state.current_stage,className:"text-left",id:"navbar-dropdown"},i.a.createElement(g.a.Item,null,"1. Visualization"),i.a.createElement(g.a.Item,null,"2. Debiasing "),i.a.createElement(g.a.Item,null,"3. Discussion "))))}}]),a}(n.Component)),k=(a(83),function(e){Object(m.a)(a,e);var t=Object(d.a)(a);function a(){return Object(s.a)(this,a),t.apply(this,arguments)}return Object(u.a)(a,[{key:"render",value:function(){return i.a.createElement("div",{className:"visual-dataset"},i.a.createElement("ul",null,i.a.createElement("li",null," ",i.a.createElement("input",{type:"radio",name:"dataset",value:"data1",defaultChecked:!0})," Dataset 1"),i.a.createElement("li",null," ",i.a.createElement("input",{type:"radio",name:"dataset",value:"data2"})," Dataset 2 "),i.a.createElement("li",null," ",i.a.createElement("input",{type:"radio",name:"dataset",value:"data3"})," Dataset 3 ")))}}]),a}(n.Component)),w=function(e){Object(m.a)(a,e);var t=Object(d.a)(a);function a(){return Object(s.a)(this,a),t.apply(this,arguments)}return Object(u.a)(a,[{key:"render",value:function(){return i.a.createElement("div",{className:"visual-dataset visual-model-new"},i.a.createElement("ul",null,i.a.createElement("li",null," ",i.a.createElement("input",{type:"radio",name:"model",value:"model1",defaultChecked:!0})," Model 1"),i.a.createElement("li",null," ",i.a.createElement("input",{type:"radio",name:"model",value:"model2"})," Model 2 "),i.a.createElement("li",null," ",i.a.createElement("input",{type:"radio",name:"model",value:"model3"})," Model 3 ")))}}]),a}(n.Component),x=a(105),O={labels:["Scatter1","Scatter2"],datasets:[{backgroundColor:"rgba(75,192,192,0.6)",pointBorderColor:"rgba(75,192,192,1)",pointHoverBackgroundColor:"rgba(75,192,192,1)",pointHoverBorderColor:"rgba(220,220,220,1)",pointBackgroundColor:"#fff",label:"Toxic speech",pointRadius:5,data:[]},{backgroundColor:"rgba(56, 135, 111, 0.6)",pointBorderColor:"rgba(56, 135, 111,1)",pointHoverBackgroundColor:"rgba(56, 135, 111,1)",pointHoverBorderColor:"rgba(56, 135, 111,1)",pointBackgroundColor:"#fff",label:"Non-Toxic speech",pointRadius:5,data:[]}]},C={scales:{xAxes:[{gridLines:{drawOnChartArea:!1,color:"#131c2b"},scaleLabel:{display:!0,labelString:"Toxicity probability"},ticks:{suggestedMin:0,maxTicksLimit:5,suggestedMax:1}}],yAxes:[{gridLines:{drawOnChartArea:!1,color:"#131c2b"},scaleLabel:{display:!0,labelString:"AAE dialect probability"},ticks:{suggestedMin:0,maxTicksLimit:5,suggestedMax:1}}]}},_=function(e){Object(m.a)(a,e);var t=Object(d.a)(a);function a(){return Object(s.a)(this,a),t.apply(this,arguments)}return Object(u.a)(a,[{key:"componentDidMount",value:function(){this.getResult()}},{key:"componentDidUpdate",value:function(){this.getResult()}},{key:"getResult",value:function(){fetch("/classifier").then((function(e){return e.json()})).then((function(e){var t=[],a=[];e.toxicity.map((function(n,i){n>.5?t.push({x:n,y:e.dialect[i]}):a.push({x:n,y:e.dialect[i]})})),O.datasets[0].data=t,O.datasets[1].data=a,console.log(O)}))}},{key:"render",value:function(){return i.a.createElement("div",{className:"text-center"},i.a.createElement(x.Scatter,{data:O,options:C}))}}]),a}(n.Component),j=a(57),N=a(33),T=function(e){Object(m.a)(a,e);var t=Object(d.a)(a);function a(e){var n;return Object(s.a)(this,a),(n=t.call(this,e)).closeTour=function(){n.setState({isTourOpen:!1})},n.disableBody=function(e){return Object(N.a)(e)},n.enableBody=function(e){return Object(N.b)(e)},n.state={dataset_active:"active",model_active:"",isTourOpen:!1},n}return Object(u.a)(a,[{key:"changeActiveState",value:function(e){console.log(e),"dataset-tab"===e&&""===this.state.dataset_active?this.setState({dataset_active:"active",model_active:""}):"model-tab"===e&&""===this.state.model_active&&this.setState({dataset_active:"",model_active:"active"})}},{key:"changeContent",value:function(){return"active"===this.state.dataset_active?i.a.createElement(k,null):i.a.createElement(w,null)}},{key:"componentDidMount",value:function(){this.setState({isTourOpen:!0})}},{key:"render",value:function(){var e=this,t=[{selector:"",content:function(){return i.a.createElement("div",null,i.a.createElement("h3",{className:"text-center"}," Visualizing the Result "),i.a.createElement("p",null," In this step you can see the result of the model that you have made in the previous step, and also interact with the components of the process to see how it affect the fairness of a model"))}},{selector:".scatter-chart",content:function(){return i.a.createElement("div",null,i.a.createElement("h3",{style:{textAlign:"center"}}," Graph "),i.a.createElement("p",null," This graph plot each of the feedback\u2019s probability of being toxic against the probability of it using AAE dialect. The higher its toxic probability, the higher it chance to be classified as toxic "),i.a.createElement("p",null," The higher its toxic probability, the higher it chance to be classified as toxic. On the other hand, the higher its AAE dialect probability, the higher it is to come from African American students"))}},{selector:".result-box",content:function(){return i.a.createElement("div",null,i.a.createElement("h3",{className:"text-center"}," Result Box "),i.a.createElement("p",null," The result box display not only the accuracy result for the model, but also the racial bias of the model "),i.a.createElement("p",null," The fairness metrics is determined as how non-discriminatory is the classifier."))}},{selector:".interact-component",content:function(){return i.a.createElement("div",null,i.a.createElement("h3",{className:"text-center"}," Dataset and Model "),i.a.createElement("p",null," In this section, you can change the model and dataset used for classification. "),i.a.createElement("p",null," Try several combinations to see how they interact with each toher."))}},{selector:".question-btn",content:function(){return i.a.createElement("div",null,i.a.createElement("h3",{className:"text-center"}," Explore and Observe "),i.a.createElement("p",null," There will be a few questions in the next step, so explore and observe as much as you can. "),i.a.createElement("p",null," Once you\u2019re done, click the question box on the top right corner. Don\u2019t worry, you can go back again if you want to"))},position:"middle"}];return i.a.createElement("div",{className:"visualization page-box"},i.a.createElement("div",{className:"vis-header"},i.a.createElement("h1",null," Abusive Speech Detection Result ")),i.a.createElement(p.a,{className:"visual-container"},i.a.createElement(f.a,{md:{span:4,offset:1}},i.a.createElement("div",{className:"scatter-chart"},i.a.createElement(_,null))),i.a.createElement(f.a,{md:{span:4,offset:2}},i.a.createElement("div",{className:"interact-component"},i.a.createElement("ul",{className:"choices"},i.a.createElement("li",{className:this.state.dataset_active,id:"dataset-tab",onClick:function(t){return e.changeActiveState(t.currentTarget.id)}}," Dataset "),i.a.createElement("li",{className:this.state.model_active,id:"model-tab",onClick:function(t){return e.changeActiveState(t.currentTarget.id)}}," Model ")),i.a.createElement("div",{className:"interact-container shadow-lg"},this.changeContent())),i.a.createElement("div",{className:"result-box"},i.a.createElement("h2",null," Result "),i.a.createElement("ul",null,i.a.createElement("li",null," Precision: 0.76 "),i.a.createElement("li",null," Recall: 0.89 "),i.a.createElement("li",null," Fairness metrics: ___ "))))),i.a.createElement(j.a,{steps:t,isOpen:this.state.isTourOpen,onRequestClose:this.closeTour,onAfterOpen:this.disableBody,onBeforeClose:this.enableBody}))}}]),a}(n.Component),A=(a(229),function(e){Object(m.a)(a,e);var t=Object(d.a)(a);function a(){return Object(s.a)(this,a),t.apply(this,arguments)}return Object(u.a)(a,[{key:"render",value:function(){return i.a.createElement("div",{className:"evaluation page-box"},i.a.createElement("h1",null," Evaluation and Questions "),i.a.createElement("p",null," After building the model and see the visualization of the result, here are some questions that you need to answer"),i.a.createElement("p",null," In case you need to see the visualization again, you can click the result button on the right corner "),i.a.createElement("form",null,i.a.createElement("label",null," 1. Based on the visualization and the result, do you find any noteworthy finding? What do you think cause this? "),i.a.createElement("textarea",null),i.a.createElement("label",null," 2. Once you try several other datasets, did you notice any different between datasets? What do you think cause this? "),i.a.createElement("textarea",null),i.a.createElement("label",null," 3. Which dataset do you think is better out of the ones that you try? Why do you think so? "),i.a.createElement("textarea",null),i.a.createElement("label",null,' 4. From the definitions of the metrics that are shown in the "model" tab, which one do you think is the fairest for both groups? Why?  '),i.a.createElement("textarea",null),i.a.createElement("label",null," 5. Try and change the metrics several times. Did you notice any changes? (e.g in term of distribution and accuracy) "),i.a.createElement("textarea",null),i.a.createElement("label",null," 6. Now that you've tried several metrics, which one do you think is the fairest for both groups? Why? "),i.a.createElement("textarea",null)),i.a.createElement("div",{className:"text-center"},i.a.createElement(h,{name:"Submit",link:"/bias-awareness-platform/#/mitigation"})))}}]),a}(n.Component)),S=(a(230),function(e){Object(m.a)(a,e);var t=Object(d.a)(a);function a(){return Object(s.a)(this,a),t.apply(this,arguments)}return Object(u.a)(a,[{key:"chooseAlgo",value:function(){var e=this,t=i.a.createElement("tr",null,i.a.createElement("td",{onClick:function(t){return e.handleClick(t.currentTarget.id)},id:"reject-option"},i.a.createElement("h3",null," Reject Option Classification "),i.a.createElement("p",null," Changes prediction result from a classifier to make it fairer ")),i.a.createElement("td",{onClick:function(t){return e.handleClick(t.currentTarget.id)},id:"equal-odd"},i.a.createElement("h3",null," Equalized odds "),i.a.createElement("p",null," Modify the predicted labels using an optimized scheme ")),i.a.createElement("td",{onClick:function(t){return e.handleClick(t.currentTarget.id)},id:"calibrated-odd"},i.a.createElement("h3",null," Calibrated Equalized odds "),i.a.createElement("p",null," Optimize over calibrated score to make the prediction fairer "))),a=i.a.createElement("tr",null,i.a.createElement("td",{onClick:function(t){return e.handleClick(t.currentTarget.id)},id:"advers-debias"},i.a.createElement("h3",null," Adversarial Debiasing "),i.a.createElement("p",null," Use adversarial technique to maximize accuracy and reduce evidence of protected attributes ")),i.a.createElement("td",{onClick:function(t){return e.handleClick(t.currentTarget.id)},id:"prejudice-remove"},i.a.createElement("h3",null," Prejudice Remover "),i.a.createElement("p",null," Adds a discrimination-aware regularization term to learning objective ")),i.a.createElement("td",{onClick:function(t){return e.handleClick(t.currentTarget.id)},id:"meta-fair"},i.a.createElement("h3",null," Meta Fair Classifier "),i.a.createElement("p",null," Take fairness metrics as a part of input and optimize based on the metrics "))),n=i.a.createElement("tr",null,i.a.createElement("td",{onClick:function(t){return e.handleClick(t.currentTarget.id)},id:"optimize-pre"},i.a.createElement("h3",null," Optimized Pre-Processing "),i.a.createElement("p",null," Modifies the training data features and label ")),i.a.createElement("td",{onClick:function(t){return e.handleClick(t.currentTarget.id)},id:"reweighing"},i.a.createElement("h3",null," Reweighing "),i.a.createElement("p",null," Modifies the weight of different training examples ")),i.a.createElement("td",{onClick:function(t){return e.handleClick(t.currentTarget.id)},id:"disparate"},i.a.createElement("h3",null," Disparate Impact Remover "),i.a.createElement("p",null," Edit features value to improve group fairness ")),i.a.createElement("td",{onClick:function(t){return e.handleClick(t.currentTarget.id)},id:"fair-learning"},i.a.createElement("h3",null," Fair Learning Representation "),i.a.createElement("p",null," Obfuscating information about the protected attributes ")));return"dataset"===this.props.selected?n:"classifier"===this.props.selected?a:"predict"===this.props.selected?t:void 0}},{key:"handleClick",value:function(e){window.location.href="/bias-awareness-platform/#/comparison?algo="+e}},{key:"render",value:function(){return i.a.createElement("div",{className:"dataset-algo text-center"},i.a.createElement("table",{className:"algo-title text-center"},i.a.createElement("tbody",null,this.chooseAlgo())))}}]),a}(n.Component)),D=a(231),R=a(232),B=a(233),M=a(234),I=a(235),z=a(236),P=function(e){Object(m.a)(a,e);var t=Object(d.a)(a);function a(e){var n;return Object(s.a)(this,a),(n=t.call(this,e)).state={dataset_src:D,classifier_src:B,predict_src:I,selected:"none"},n}return Object(u.a)(a,[{key:"choosePhase",value:function(e){console.log(e),"dataset"===e?this.setState({dataset_src:D,classifier_src:M,predict_src:z,selected:"dataset"}):"classifier"===e?this.setState({dataset_src:R,classifier_src:B,predict_src:z,selected:"classifier"}):this.setState({dataset_src:R,classifier_src:M,predict_src:I,selected:"predict"})}},{key:"render",value:function(){var e=this;return i.a.createElement("div",{className:"page-box mitigation"},i.a.createElement("h1",null," Bias Mitigation "),i.a.createElement("p",null," Changing the dataset into a fairer dataset may help reducing the racial bias, but a fair dataset doesn't always happen in real settings. In this case, we could resort to mitigate the bias instead "),i.a.createElement("p",null," There are few concrete ways to mitigate the racial bias that may occur"),i.a.createElement("h2",{className:"text-center"}," Select a phase to add mitigation "),i.a.createElement(p.a,{className:"text-center phase-choice"},i.a.createElement(f.a,{md:{span:2,offset:3}}," ",i.a.createElement("img",{src:this.state.dataset_src,alt:"",id:"dataset",onClick:function(t){return e.choosePhase(t.currentTarget.id)}})," "),i.a.createElement(f.a,{md:2}," ",i.a.createElement("img",{src:this.state.classifier_src,alt:"",id:"classifier",onClick:function(t){return e.choosePhase(t.currentTarget.id)}})," "),i.a.createElement(f.a,{md:2},"  ",i.a.createElement("img",{src:this.state.predict_src,alt:"",id:"predict",onClick:function(t){return e.choosePhase(t.currentTarget.id)}})," ")),i.a.createElement(S,{selected:this.state.selected}))}}]),a}(n.Component),q=(a(237),a(28)),F=a(15),L={"reject-option":"Reject Option Classification","equal-odd":"Equalized Odds","calibrated-odd":"Calibrated Equalized Odds","advers-debias":"Adversarial Debiasing","prejudice-remove":"Prejudice Remover","meta-fair":"Meta Fair Classifier","optimize-pre":"Optimized Pre-Processing",reweighing:"Reweighing",disparate:"Disparate Impact Remover","fair-learning":"Fair Learning Representation"},W=function(e){Object(m.a)(a,e);var t=Object(d.a)(a);function a(e){var n;return Object(s.a)(this,a),(n=t.call(this,e)).state={bias_dropdown:"hide",algo:"Select your algo"},n.showDropdown=n.showDropdown.bind(Object(q.a)(n)),n}return Object(u.a)(a,[{key:"showDropdown",value:function(){"hide"===this.state.bias_dropdown?this.setState({bias_dropdown:"show"}):"show"===this.state.bias_dropdown&&this.setState({bias_dropdown:"hide"})}},{key:"changeAlgo",value:function(e){window.location.href="/bias-awareness-platform/#/comparison?algo="+e,this.setState({algo:L[e]})}},{key:"componentDidMount",value:function(){var e=window.location.href.split("=");void 0===e[1]?this.setState({algo:"Choose the mitigation algorithm..."}):this.setState({algo:L[e[1]]})}},{key:"iterateAlgoList",value:function(){var e=this,t=[];for(var a in L)t.push([a,L[a]]);return t.map((function(t){return i.a.createElement(F.a.Item,{id:t[0],onClick:function(t){return e.changeAlgo(t.currentTarget.id)}},t[1])}))}},{key:"render",value:function(){return i.a.createElement("div",{id:"comparison"},i.a.createElement("h2",{className:"text-center"}," Comparison "),i.a.createElement(p.a,{className:"compare"},i.a.createElement(f.a,{className:"text-center algo-half"},i.a.createElement("h3",null," Without bias mitigation "),i.a.createElement(_,null),i.a.createElement("div",{className:"result-box"},i.a.createElement("h2",null," Result "),i.a.createElement("ul",null,i.a.createElement("li",null," Precision: 0.76 "),i.a.createElement("li",null," Recall: 0.89 "),i.a.createElement("li",null," Fairness metrics: ___ ")))),i.a.createElement(f.a,{className:"text-center algo-half"},i.a.createElement("h3",{className:"algo-heading"}," Bias Mitigation: "),i.a.createElement(F.a,{className:"algo-dropdown"},i.a.createElement(F.a.Toggle,null," ",this.state.algo," "),i.a.createElement(F.a.Menu,null,this.iterateAlgoList())),i.a.createElement(_,null),i.a.createElement("div",{className:"result-box"},i.a.createElement("h2",null," Result "),i.a.createElement("ul",null,i.a.createElement("li",null," Precision: 0.76 "),i.a.createElement("li",null," Recall: 0.89 "),i.a.createElement("li",null," Fairness metrics: ___ "))))))}}]),a}(n.Component),H=function(e){Object(m.a)(a,e);var t=Object(d.a)(a);function a(){return Object(s.a)(this,a),t.apply(this,arguments)}return Object(u.a)(a,[{key:"render",value:function(){return i.a.createElement("div",{className:"evaluate"},i.a.createElement("h5",null," Try changing the bias mitigation method several times. You can change the bias mitigation method directly on the comparison, or going back to the previous page using the mitigation button the top right corner. For each form, use exactly one bias mitigation. You can submit the form multiple times"),i.a.createElement("form",null,i.a.createElement("label",null," 1. Which bias mitigation do you use "),i.a.createElement("textarea",null),i.a.createElement("label",null," 2. Is there any increase or decrease in fairness after the bias mitigation is applied? "),i.a.createElement("textarea",null),i.a.createElement("label",null," 3. Is there any increase or decrease in accuracy after the bias mitigation is applied "),i.a.createElement("textarea",null),i.a.createElement("label",null," 4. Based on the accuracy-fairness tradeoff, would you use this bias mitigation algorithm for this scenario in particular?  "),i.a.createElement("textarea",null)),i.a.createElement(h,{name:"Submit",link:"/bias-awareness-platform/#/fin",className:"text-center"}))}}]),a}(n.Component),U=function(e){Object(m.a)(a,e);var t=Object(d.a)(a);function a(e){var n;return Object(s.a)(this,a),(n=t.call(this,e)).state={compare_active:"active",evaluate_active:""},n}return Object(u.a)(a,[{key:"changeContent",value:function(e){console.log(e),"comparison-tab"===e?this.setState({compare_active:"active",evaluate_active:""}):this.setState({compare_active:"",evaluate_active:"active"})}},{key:"returnContent",value:function(){return"active"===this.state.compare_active?i.a.createElement(W,null):"active"===this.state.evaluate_active?i.a.createElement(H,null):void 0}},{key:"render",value:function(){var e=this;return i.a.createElement("div",{className:"comparison page-box"},i.a.createElement("h1",null," Comparison and Evaluation "),i.a.createElement("p",null," After bias mitigation, here are the comparison between the classifier result before bias mitigation is applied and after the bias mitigation is applied."),i.a.createElement("ul",{className:"choices"},i.a.createElement("li",{className:this.state.compare_active,id:"comparison-tab",onClick:function(t){return e.changeContent(t.currentTarget.id)}}," Comparison "),i.a.createElement("li",{className:this.state.evaluate_active,id:"evaluation-tab",onClick:function(t){return e.changeContent(t.currentTarget.id)}}," Evaluation ")),i.a.createElement("div",{className:"interact-container"},this.returnContent()))}}]),a}(n.Component),G=a(112),V=a(113),Y=a(110),J=function(e){Object(m.a)(n,e);var t=Object(d.a)(n);function n(e){var a;return Object(s.a)(this,n),(a=t.call(this,e)).closeTour=function(){a.setState({isTourOpen:!1})},a.disableBody=function(e){return Object(N.a)(e)},a.enableBody=function(e){return Object(N.b)(e)},a.state={dataset_active:"active",model_active:"",words_input:"",words_list:[],isTourOpen:!1},a.handleInputChange=a.handleInputChange.bind(Object(q.a)(a)),a.handleInputDown=a.handleInputDown.bind(Object(q.a)(a)),a}return Object(u.a)(n,[{key:"changeActiveState",value:function(e){console.log(e),"dataset-tab"===e&&""===this.state.dataset_active?this.setState({dataset_active:"active",model_active:""}):"model-tab"===e&&""===this.state.model_active&&this.setState({dataset_active:"",model_active:"active"})}},{key:"changeContent",value:function(){return"active"===this.state.dataset_active?i.a.createElement(k,null):i.a.createElement(w,null)}},{key:"componentDidMount",value:function(){this.setState({isTourOpen:!0})}},{key:"handleInputChange",value:function(e){this.setState({words_input:e.target.value})}},{key:"handleInputDown",value:function(e){if(13===e.keyCode){e.preventDefault();var t=e.target.value;console.log(t),this.setState((function(e){return{words_list:[].concat(Object(G.a)(e.words_list),[t]),words_input:""}}))}}},{key:"handleRemove",value:function(e){var t=this;return function(){t.setState((function(t){return{words_list:t.words_list.filter((function(t,a){return a!==e}))}}))}}},{key:"render",value:function(){var e=this,t=[{selector:"",content:function(){return i.a.createElement("div",null,i.a.createElement("h3",{className:"text-center"}," Exploring Abusive Speech Detection "),i.a.createElement("p",null," In this page, you can interactively explore the combination of different datasets and models for the abusive speech detection, and observe how it affect the distribution and fairness of the result"))}},{selector:"#interactive-controller",content:function(){return i.a.createElement("div",null,i.a.createElement("h3",{className:"text-center"}," Dataset and Model "),i.a.createElement("p",null," In this part, you can change the model and dataset used for classification. "),i.a.createElement("p",null,' Try several combinations to see how they interact with each other. Don\'t forget to click the "Build Model" button everytime you want to try the new combination'))}},{selector:".scatter-chart",content:function(){return i.a.createElement("div",null,i.a.createElement("h3",{style:{textAlign:"center"}}," Graph "),i.a.createElement("p",null," This graph plot each of the feedback\u2019s probability of being toxic against the probability of it using AAE dialect. The higher its toxic probability, the higher it chance to be classified as toxic "),i.a.createElement("p",null," The higher its toxic probability, the higher it chance to be classified as toxic. On the other hand, the higher its AAE dialect probability, the higher it is to come from African American students"))}},{selector:"#visual-result",content:function(){return i.a.createElement("div",null,i.a.createElement("h3",{className:"text-center"}," Result Box "),i.a.createElement("p",null," The result box display not only the accuracy result for the model, but also the distribution of each class with each label "))}},{selector:".associated-words",content:function(){return i.a.createElement("div",null,i.a.createElement("h3",{className:"text-center"}," Associated Words "),i.a.createElement("p",null," In this part, you can enter word(s) that you want to include in the dataset. For example, if you inputted 'ugly' and press ENTER, then the dataset will only include tweets that contain the word 'ugly' in it, and exclude the rest."),i.a.createElement("p",null,' Once you put all the words you want to include, don\'t forget to click the "Reload" button to reload the model!'))},position:"middle"}];return i.a.createElement("div",{className:"visualization-new"},i.a.createElement("div",{className:"visualization-new-container"},i.a.createElement("div",{className:"graph-left"},i.a.createElement("h1",null," Abusive Speech Detection Result "),i.a.createElement("div",{className:"scatter-chart"},i.a.createElement(_,{width:10,height:10})),i.a.createElement("div",{className:"associated-words"},i.a.createElement("form",{className:"form-inline"},i.a.createElement("label",null," Associated words: "),i.a.createElement("input",{className:"form-control ml-4",type:"text",value:this.state.words_input,onChange:this.handleInputChange,onKeyDown:this.handleInputDown}),i.a.createElement(V.a,{key:"top",placement:"top",overlay:i.a.createElement(Y.a,{id:"tooltip-".concat("top")},"Specify words that must be included in the dataset and exclude the rest of dataset. For example, inputting 'ugly' means the data processed are only tweets that contain 'ugly' in it.")},i.a.createElement("img",{src:a(238),alt:"",id:"help-tag"})),i.a.createElement("button",{className:"btn btn-green ml-4",onClick:function(e){e.preventDefault()}}," Reload ")),i.a.createElement("ul",{className:"word-container"},this.state.words_list.map((function(t,n){return i.a.createElement("li",{key:n,className:"word-tag"},i.a.createElement("span",null," ",t," "),i.a.createElement("img",{src:a(239),alt:"",onClick:e.handleRemove(n)}))}))))),i.a.createElement("div",{className:"interactive-right"},i.a.createElement("div",{id:"interactive-controller"},i.a.createElement("div",{className:"d-flex interact-tab"},i.a.createElement("div",{className:"interactive-choice "+this.state.dataset_active,id:"dataset-tab",onClick:function(t){return e.changeActiveState(t.currentTarget.id)}}," DATASET "),i.a.createElement("div",{className:"interactive-choice "+this.state.model_active,id:"model-tab",onClick:function(t){return e.changeActiveState(t.currentTarget.id)}}," MODEL ")),i.a.createElement("div",{className:"interact-container"},this.changeContent()),i.a.createElement("div",{className:"load-btn"},i.a.createElement("button",{type:"button",className:"btn btn-green"}," Build Model "))),i.a.createElement("div",{id:"visual-result"},i.a.createElement("h3",null," Result "),i.a.createElement("div",{id:"result-table"},i.a.createElement("table",{className:"table"},i.a.createElement("thead",null,i.a.createElement("tr",null,i.a.createElement("th",{scope:"col"},"Class"),i.a.createElement("th",{scope:"col"},"Pblack"),i.a.createElement("th",{scope:"col"},"Pwhite"),i.a.createElement("th",{scope:"col"},"Pblack/Pwhite"))),i.a.createElement("tbody",null,i.a.createElement("tr",null,i.a.createElement("th",{scope:"row"},"Racism"),i.a.createElement("td",null," 0.001 "),i.a.createElement("td",null," 0.003 "),i.a.createElement("td",null," 0.505 ")),i.a.createElement("tr",null,i.a.createElement("th",{scope:"row"},"Sexism"),i.a.createElement("td",null," 0.083 "),i.a.createElement("td",null," 0.048 "),i.a.createElement("td",null," 1.724 ")))))))),i.a.createElement(j.a,{steps:t,isOpen:this.state.isTourOpen,onRequestClose:this.closeTour,onAfterOpen:this.disableBody,onBeforeClose:this.enableBody}))}}]),n}(n.Component),K=function(e){Object(m.a)(a,e);var t=Object(d.a)(a);function a(e){var n;return Object(s.a)(this,a),(n=t.call(this,e)).state={current_step:1,curr_time:""},n}return Object(u.a)(a,[{key:"componentDidUpdate",value:function(){console.log("updated in parent"),this.updateCurrentStep()}},{key:"componentDidMount",value:function(){console.log(this.props.location),this.updateCurrentStep()}},{key:"updateCurrentStep",value:function(){var e=this.props.location.pathname;e.includes("visualization")&&2!==this.state.current_step?this.setState({current_step:2}):e.includes("evaluation")&&3!==this.state.current_step?this.setState({current_step:3}):e.includes("mitigation")&&4!==this.state.current_step?this.setState({current_step:4}):e.includes("comparison")&&5!==this.state.current_step?this.setState({current_step:5}):e.includes("fin")&&6!==this.state.current_step&&this.setState({current_step:6})}},{key:"render",value:function(){return i.a.createElement("div",{className:"main-application"},i.a.createElement(y,null),i.a.createElement(o.c,null,i.a.createElement(o.a,{path:"/code",component:b}),i.a.createElement(o.a,{path:"/visualization",component:T}),i.a.createElement(o.a,{path:"/evaluation",component:A}),i.a.createElement(o.a,{path:"/mitigation",component:P}),i.a.createElement(o.a,{path:"/comparison",component:U}),i.a.createElement(o.a,{path:"/test",component:J})))}}]),a}(n.Component);var Q=function(){return i.a.createElement("div",null,i.a.createElement(o.c,null,i.a.createElement(o.a,{exact:!0,path:"/",component:E}),i.a.createElement(o.a,{path:"/",component:K})))};Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));var $=function(e){Object(m.a)(a,e);var t=Object(d.a)(a);function a(){return Object(s.a)(this,a),t.apply(this,arguments)}return Object(u.a)(a,[{key:"componentDidUpdate",value:function(e){this.props.location.pathname!==e.location.pathname&&window.scrollTo(0,0)}},{key:"render",value:function(){return null}}]),a}(i.a.Component),X=Object(o.f)($);r.a.render(i.a.createElement(c.a,null,i.a.createElement(X,null),i.a.createElement(o.a,{path:"/",component:Q})),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then((function(e){e.unregister()})).catch((function(e){console.error(e.message)}))},83:function(e,t,a){}},[[118,1,2]]]);
//# sourceMappingURL=main.86c67f58.chunk.js.map